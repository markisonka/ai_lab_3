{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas\n",
    "import collections\n",
    "import collections\n",
    "from torchnlp import *\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение однослойной двухноправленной сети LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задаём Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# токенизацией по словам\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "# длина обрабатываемой последовательности токенов\n",
    "nchars = 100\n",
    "num_layers=3\n",
    "test_str_orig = \"Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли у него по бокам. Лорд Малфой повернул голову, слишком слабо, чтобы считать это знаком внимания, но всё-таки в направлении профессора Защиты.\"\n",
    "test_str_slov = \"Беловолосый человек остановился у самого\"\n",
    "test_str = test_str_orig[:nchars]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета с токенизацией по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Building vocab...\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_HP(ngrams=1,min_freq=1):\n",
    "    global vocab, tokenizer\n",
    "    print(\"Loading dataset...\")\n",
    "    train_dataset = pandas.read_csv('./dataHPMRM.csv')[\"text\"]\n",
    "    train_dataset = list(train_dataset)\n",
    "    print('Building vocab...')\n",
    "    counter = collections.Counter()\n",
    "    for line in train_dataset:\n",
    "        counter.update(torchtext.data.utils.ngrams_iterator(tokenizer(line),ngrams=ngrams))\n",
    "    vocab = torchtext.vocab.vocab(counter, min_freq=min_freq)\n",
    "    return train_dataset,vocab\n",
    "train_dataset,vocab_slov=load_dataset_HP()\n",
    "vocab_size_slov = len(vocab_slov)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посимвольная токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 167\n",
      "Encoding of 'a' is 120\n",
      "Character with code 13 is н\n"
     ]
    }
   ],
   "source": [
    "def char_tokenizer(words):\n",
    "    return list(words) #[word for word in words]\n",
    "\n",
    "counter = collections.Counter()\n",
    "for line in train_dataset:\n",
    "    counter.update(char_tokenizer(line))\n",
    "vocab = torchtext.vocab.vocab(counter)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size = {vocab_size}\")\n",
    "print(f\"Encoding of 'a' is {vocab.get_stoi()['a']}\")\n",
    "print(f\"Character with code 13 is {vocab.get_itos()[13]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции Кодирования токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_hash = {}\n",
    "def encode(x,voc=None,unk=0,tokenizer=tokenizer):\n",
    "    global stoi_hash\n",
    "    v = vocab if voc is None else voc\n",
    "    if v in stoi_hash.keys():\n",
    "        stoi = stoi_hash[v]\n",
    "    else:\n",
    "        stoi = v.get_stoi()\n",
    "        stoi_hash[v]=stoi        \n",
    "    return [stoi.get(s,unk) for s in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ф-ии Кодирование токинов по словам\n",
    "def enc_slov(x):\n",
    "    return torch.LongTensor(encode(x,voc=vocab_slov,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ф-ии Кодирование токинов по символам\n",
    "def enc(x):\n",
    "    return torch.LongTensor(encode(x,voc=vocab,tokenizer=char_tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция Создания Батча в эпохе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(s,nchars=nchars):\n",
    "    ins = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    outs = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    for i in range(len(s)-nchars):\n",
    "        ins[i] = enc(s[i:i+nchars])\n",
    "        outs[i] = enc(s[i+1:i+nchars+1])\n",
    "    return ins,outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_slov(s,nchars=nchars):\n",
    "    leng = len(enc_slov(s))\n",
    "    inps = torch.zeros(leng-nchars,nchars,dtype=torch.long,device=device)\n",
    "    outs = torch.zeros(leng-nchars,nchars,dtype=torch.long,device=device)\n",
    "    for i in range(leng-nchars):\n",
    "        inps[i] = enc_slov(s)[i:i+nchars]\n",
    "        outs[i] = enc_slov(s)[i+1:i+nchars+1]\n",
    "    return inps,outs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Однослойная двухноправленная сеть LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBidirectionalGenerator(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.rnn = torch.nn.LSTM(self.vocab_size,hidden_dim,batch_first=True,bidirectional=True,num_layers=1)\n",
    "        self.fc = torch.nn.Linear(hidden_dim*2, self.vocab_size)\n",
    "\n",
    "    def forward(self, x, s=None):\n",
    "        x = torch.nn.functional.one_hot(x,self.vocab_size).to(torch.float32)\n",
    "        x,s = self.rnn(x,s)\n",
    "        return self.fc(x),s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генератор следующией послдовательности символов/слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(net,size=100,start='Сегодня '):\n",
    "    chars = list(start)\n",
    "    out, s = net(enc(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        nc = torch.argmax(out[0][-1])\n",
    "        chars.append(vocab.get_itos()[nc])\n",
    "        out = net(nc.view(1,-1), s)\n",
    "    return ''.join(chars)\n",
    "        \n",
    "def generate_slov(net,size=100,start='Сегодня '):\n",
    "    chars = start\n",
    "    out, s = net(enc_slov(start).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        nc = torch.argmax(out[0][-1])\n",
    "        chars+= \" \" + (vocab_slov.get_itos()[nc])\n",
    "        out, s = net(nc.view(1,-1), s)\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мягкая генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_soft(net,size=100,start='Сегодня маг ',temperature=1.0,enc=enc):\n",
    "    chars = list(start)\n",
    "    out, s = net(enc(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        #nc = torch.argmax(out[0][-1])\n",
    "        out_dist = out[0][-1].div(temperature).exp()\n",
    "        nc = torch.multinomial(out_dist,1)[0]\n",
    "        chars.append(vocab.get_itos()[nc])\n",
    "        out, s = net(nc.view(1,-1), s)\n",
    "    return ''.join(chars)\n",
    "\n",
    "def generate_soft_slov(net,size=100,start='Сегодня маг ',temperature=1.0,enc=enc):\n",
    "    chars = start\n",
    "    out, s = net(enc_slov(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        #nc = torch.argmax(out[0][-1])\n",
    "        out_dist = out[0][-1].div(temperature).exp()\n",
    "        nc = torch.multinomial(out_dist,1)[0]\n",
    "        chars += \" \" + vocab_slov.get_itos()[nc]\n",
    "        out, s = net(nc.view(1,-1), s)\n",
    "    return ''.join(chars)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_dataset,val_dataset,num_epochs, optimizer, scheduler, get_batch, generate, slov = False):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        for phase in [\"T\",\"V\"]:\n",
    "            if phase == 'T':\n",
    "                net.train()  # Установить модель в режим обучения\n",
    "                dataset=train_dataset\n",
    "            else:\n",
    "                net.eval()   #Установить модель в режим оценки\n",
    "                dataset=val_dataset\n",
    "            \n",
    "            epoch_loss = 0.0    \n",
    "            for i,x in enumerate(dataset):\n",
    "                \n",
    "                # x[0] is class label, x is text\n",
    "                if slov:\n",
    "                    leng = len(enc_slov(x))\n",
    "                else:\n",
    "                    leng = len(x)\n",
    "                    \n",
    "                if leng-nchars<10:\n",
    "                    continue\n",
    "\n",
    "                text_in, text_out = get_batch(x,nchars=nchars)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'T'):\n",
    "                    out, s = net(text_in)\n",
    "                    loss = torch.nn.functional.cross_entropy(out.view(-1,vocab_size),text_out.flatten()) #cross_entropy(out,labels)\n",
    "                    if phase == 'T':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    else:\n",
    "                        # scheduler.step(loss.item())\n",
    "                        pass\n",
    "                epoch_loss+=loss.item()\n",
    "                # if i%100==0:\n",
    "                #     print(f\"{i}/{len(dataset)} Current loss {phase} = {epoch_loss/(i+1)}\")\n",
    "            print(f\"Current loss {phase} = {epoch_loss / len(dataset)}\")\n",
    "            if phase == 'V':\n",
    "                print(generate(net,start=test_str))    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение Simple RNN с посимвольной токенизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=LSTMBidirectionalGenerator(vocab_size,nchars).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.9,patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "Current loss T = 0.02161425632493154\n",
      "Current loss V = 0.011223232644708338\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлиыхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхныхн\n",
      "Epoch 1/10\n",
      "Current loss T = 0.009179328164786721\n",
      "Current loss V = 0.009498662711603744\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлаБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяеБяе\n",
      "Epoch 2/10\n",
      "Current loss T = 0.008387930928878531\n",
      "Current loss V = 0.009069524093135052\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли:ББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББ\n",
      "Epoch 3/10\n",
      "Current loss T = 0.008086066164769649\n",
      "Current loss V = 0.007836446650331954\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлиБББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББ\n",
      "Epoch 4/10\n",
      "Current loss T = 0.007877858801336722\n",
      "Current loss V = 0.007767115615225448\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлиБББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББ\n",
      "Epoch 5/10\n",
      "Current loss T = 0.007683696234428521\n",
      "Current loss V = 0.007766040787440854\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлиБББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББ\n",
      "Epoch 6/10\n",
      "Current loss T = 0.007634496604480864\n",
      "Current loss V = 0.007869520570649262\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлиБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБЬБ\n",
      "Epoch 7/10\n",
      "Current loss T = 0.007551892070560404\n",
      "Current loss V = 0.007458728366728219\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлиБББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББ\n",
      "Epoch 8/10\n",
      "Current loss T = 0.007555935226358589\n",
      "Current loss V = 0.007376465027514426\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлиБББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББ\n",
      "Epoch 9/10\n",
      "Current loss T = 0.007472247887068086\n",
      "Current loss V = 0.007436383575107283\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлиБББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББББ\n"
     ]
    }
   ],
   "source": [
    "train(net,train_dataset,train_dataset,10,optimizer, scheduler, get_batch, generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Temperature = 0.3\n",
      "Беловолосый человек остановился у самого Б — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\n",
      "\n",
      "--- Temperature = 0.8\n",
      "Беловолосый человек остановился у самого Б — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\n",
      "\n",
      "--- Temperature = 1.0\n",
      "Беловолосый человек остановился у самого Б — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\n",
      "\n",
      "--- Temperature = 1.3\n",
      "Беловолосый человек остановился у самого Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б Б\n",
      "\n",
      "--- Temperature = 1.8\n",
      "Беловолосый человек остановился у самого Б — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"--- Temperature = {i}\\n{generate_soft(net,size=300,start=test_str_slov,temperature=i ,enc=enc)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли\n"
     ]
    }
   ],
   "source": [
    "print(generate(net,size=1,start=test_str))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c05aa4aacc3846fa4cd34ace5ac6047d6b88a1f81619af340efafced5e57c11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
