{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas\n",
    "import collections\n",
    "import collections\n",
    "from torchnlp import *\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение Simple RNN с посимвольной и по-словной токенизацией"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# токенизацией по словам\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "# длина обрабатываемой последовательности токенов\n",
    "nchars = 100\n",
    "num_layers=3\n",
    "test_str_orig = \"Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли у него по бокам. Лорд Малфой повернул голову, слишком слабо, чтобы считать это знаком внимания, но всё-таки в направлении профессора Защиты.\"\n",
    "test_str_slov = \"Беловолосый человек остановился у самого\"\n",
    "test_str = test_str_orig[:nchars]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета с токенизацией по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Building vocab...\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_HP(ngrams=1,min_freq=1):\n",
    "    global vocab, tokenizer\n",
    "    print(\"Loading dataset...\")\n",
    "    train_dataset = pandas.read_csv('./dataHPMRM.csv')[\"text\"]\n",
    "    train_dataset = list(train_dataset)\n",
    "    print('Building vocab...')\n",
    "    counter = collections.Counter()\n",
    "    for line in train_dataset:\n",
    "        counter.update(torchtext.data.utils.ngrams_iterator(tokenizer(line),ngrams=ngrams))\n",
    "    vocab = torchtext.vocab.vocab(counter, min_freq=min_freq)\n",
    "    return train_dataset,vocab\n",
    "train_dataset,vocab_slov=load_dataset_HP()\n",
    "vocab_size_slov = len(vocab_slov)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посимвольная токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 167\n",
      "Encoding of 'a' is 120\n",
      "Character with code 13 is н\n"
     ]
    }
   ],
   "source": [
    "def char_tokenizer(words):\n",
    "    return list(words) #[word for word in words]\n",
    "\n",
    "counter = collections.Counter()\n",
    "for line in train_dataset:\n",
    "    counter.update(char_tokenizer(line))\n",
    "vocab = torchtext.vocab.vocab(counter)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size = {vocab_size}\")\n",
    "print(f\"Encoding of 'a' is {vocab.get_stoi()['a']}\")\n",
    "print(f\"Character with code 13 is {vocab.get_itos()[13]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции Кодирования токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_hash = {}\n",
    "def encode(x,voc=None,unk=0,tokenizer=tokenizer):\n",
    "    global stoi_hash\n",
    "    v = vocab if voc is None else voc\n",
    "    if v in stoi_hash.keys():\n",
    "        stoi = stoi_hash[v]\n",
    "    else:\n",
    "        stoi = v.get_stoi()\n",
    "        stoi_hash[v]=stoi        \n",
    "    return [stoi.get(s,unk) for s in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ф-ии Кодирование токинов по словам\n",
    "def enc_slov(x):\n",
    "    return torch.LongTensor(encode(x,voc=vocab_slov,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ф-ии Кодирование токинов по символам\n",
    "def enc(x):\n",
    "    return torch.LongTensor(encode(x,voc=vocab,tokenizer=char_tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция Создания Батча в эпохе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(s,nchars=nchars):\n",
    "    ins = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    outs = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    for i in range(len(s)-nchars):\n",
    "        ins[i] = enc(s[i:i+nchars])\n",
    "        outs[i] = enc(s[i+1:i+nchars+1])\n",
    "    return ins,outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_slov(s,nchars=nchars):\n",
    "    leng = len(enc_slov(s))\n",
    "    inps = torch.zeros(leng-nchars,nchars,dtype=torch.long,device=device)\n",
    "    outs = torch.zeros(leng-nchars,nchars,dtype=torch.long,device=device)\n",
    "    for i in range(leng-nchars):\n",
    "        inps[i] = enc_slov(s)[i:i+nchars]\n",
    "        outs[i] = enc_slov(s)[i+1:i+nchars+1]\n",
    "    return inps,outs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Однослойная однонаправленая сеть Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNGenerator(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.rnn = torch.nn.RNN(self.vocab_size,hidden_dim,batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, self.vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.one_hot(x,self.vocab_size).to(torch.float32)\n",
    "        x,h = self.rnn(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генератор следующией послдовательности символов/слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(net,size=100,start='Сегодня '):\n",
    "    chars = list(start)\n",
    "    out = net(enc(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        nc = torch.argmax(out[0][-1])\n",
    "        chars.append(vocab.get_itos()[nc])\n",
    "        out = net(nc.view(1,-1))\n",
    "    return ''.join(chars)\n",
    "        \n",
    "def generate_slov(net,size=100,start='Сегодня '):\n",
    "    chars = start\n",
    "    out = net(enc_slov(start).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        nc = torch.argmax(out[0][-1])\n",
    "        chars+= \" \" + (vocab_slov.get_itos()[nc])\n",
    "        out = net(nc.view(1,-1))\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мягкая генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_soft(net,size=100,start='Сегодня маг ',temperature=1.0,enc=enc):\n",
    "    chars = list(start)\n",
    "    out = net(enc(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        #nc = torch.argmax(out[0][-1])\n",
    "        out_dist = out[0][-1].div(temperature).exp()\n",
    "        nc = torch.multinomial(out_dist,1)[0]\n",
    "        chars.append(vocab.get_itos()[nc])\n",
    "        out = net(nc.view(1,-1))\n",
    "    return ''.join(chars)\n",
    "\n",
    "def generate_soft_slov(net,size=100,start='Сегодня маг ',temperature=1.0,enc=enc):\n",
    "    chars = start\n",
    "    out = net(enc_slov(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        #nc = torch.argmax(out[0][-1])\n",
    "        out_dist = out[0][-1].div(temperature).exp()\n",
    "        nc = torch.multinomial(out_dist,1)[0]\n",
    "        chars += \" \" + vocab_slov.get_itos()[nc]\n",
    "        out = net(nc.view(1,-1))\n",
    "    return ''.join(chars)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ф-ия обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_dataset,val_dataset,num_epochs, optimizer, scheduler, get_batch, generate, slov = False):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        for phase in [\"T\",\"V\"]:\n",
    "            if phase == 'T':\n",
    "                net.train()  # Установить модель в режим обучения\n",
    "                dataset=train_dataset\n",
    "            else:\n",
    "                net.eval()   #Установить модель в режим оценки\n",
    "                dataset=val_dataset\n",
    "            \n",
    "            epoch_loss = 0.0    \n",
    "            for i,x in enumerate(dataset):\n",
    "                \n",
    "                # x[0] is class label, x is text\n",
    "                if slov:\n",
    "                    leng = len(enc_slov(x))\n",
    "                else:\n",
    "                    leng = len(x)\n",
    "                    \n",
    "                if leng-nchars<10:\n",
    "                    continue\n",
    "\n",
    "                text_in, text_out = get_batch(x,nchars=nchars)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'T'):\n",
    "                    out = net(text_in)\n",
    "                    loss = torch.nn.functional.cross_entropy(out.view(-1,vocab_size),text_out.flatten()) #cross_entropy(out,labels)\n",
    "                    if phase == 'T':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    else:\n",
    "                        # scheduler.step(loss.item())\n",
    "                        pass\n",
    "                epoch_loss+=loss.item()\n",
    "                # if i%100==0:\n",
    "                #     print(f\"{i}/{len(dataset)} Current loss {phase} = {epoch_loss/(i+1)}\")\n",
    "            print(f\"Current loss {phase} = {epoch_loss / len(dataset)}\")\n",
    "            if phase == 'V':\n",
    "                print(generate(net,start=test_str))    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение Simple RNN с посимвольной токенизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=RNNGenerator(vocab_size,nchars).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.9,patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "Current loss T = 1.0830420300127306\n",
      "Current loss V = 1.028870946333628\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли стори стори стори стори стори стори стори стори стори стори стори стори стори стори стори стори ст\n",
      "Epoch 1/10\n",
      "Current loss T = 1.1287643617113217\n",
      "Current loss V = 1.2247824693697826\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто ст\n",
      "Epoch 2/10\n",
      "Current loss T = 1.1782178978455407\n",
      "Current loss V = 1.165402637884211\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто ст\n",
      "Epoch 3/10\n",
      "Current loss T = 1.1574416881218978\n",
      "Current loss V = 1.1554023067142574\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто ст\n",
      "Epoch 4/10\n",
      "Current loss T = 1.1435031081665974\n",
      "Current loss V = 1.1530345116896876\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто ст\n",
      "Epoch 5/10\n",
      "Current loss T = 1.1664008913766635\n",
      "Current loss V = 1.1633818693275277\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто ст\n",
      "Epoch 6/10\n",
      "Current loss T = 1.170227512605169\n",
      "Current loss V = 1.1634352622237347\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто сто ст\n",
      "Epoch 7/10\n",
      "Current loss T = 1.1759802893739866\n",
      "Current loss V = 1.1615317992465948\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по\n",
      "Epoch 8/10\n",
      "Current loss T = 1.159373582493744\n",
      "Current loss V = 1.158339458567416\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли про про про про про про про про про про про про про про про про про про про про про про про про пр\n",
      "Epoch 9/10\n",
      "Current loss T = 1.170829508851745\n",
      "Current loss V = 1.1878956408585746\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пра пр\n"
     ]
    }
   ],
   "source": [
    "train(net,train_dataset,train_dataset,10,optimizer, scheduler, get_batch, generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Temperature = 0.3\n",
      "Беловолосый человек остановился у самого по на го Нера по по пра сть берить ва верить Онали при нера по сто неро ма ста то при про сть во пра Я по по про сто сте на во несто сь сть слиму нерика прой сть вонерро ви прито мери сто о пра в но сть ста сть пра на сти нитов ка про неро про ста по понера по пра за ма о вера пра сть сть скоре пре\n",
      "\n",
      "--- Temperature = 0.8\n",
      "Беловолосый человек остановился у самогобы сиже, пала Га, и Норери чкото про повс — Га поте знна скильсесламит в ть за Вора знет ли, Я вере, сть мую, ей звся пре нелащи И пра онерошен содое вз Прелей лалаль ть Машетарри ныве ни — о лаза преза Гая, Лола Нарерио, сттди зожалла, веро — стириго см Вслакалутовра — мо нены клаза, ланы е че слит\n",
      "\n",
      "--- Temperature = 1.0\n",
      "Беловолосый человек остановился у самого о дарешавый вачено, нем ляце и Га Тымнучт, бозцы со — хос быкоятыви. паката — созалаючестьшьючтть Ода! фаросо, Га тня пруче проль Ная… мо, сть сло бунориче снитобыть иле ть. чка, зкл ― По ся пруль у. етуш-ть сто стобох» и — ви На о всты сав «Хо пря, киерымя претозаянылоноиоминане АТы ниято — гу — д\n",
      "\n",
      "--- Temperature = 1.3\n",
      "Беловолосый человек остановился у самогостовшлило лирима и Тёмирих пыем, зрдармечулькалны Дата, инда нунонема, нтисышемачушепрри уртив желимамимочи — Онасня Сей-Заза чкадакуттиг о чЛюдусяца чо. мажналдну Я Всиу ума ноговолучи сью Вомктас виолобникростох Лонче, ОДари когленосл Га Эт, рронё, … Нилазерирво, нцой.. к. Нем. нишлое нуе Церр. … \n",
      "\n",
      "--- Temperature = 1.8\n",
      "Беловолосый человек остановился у самогом змёти. чОнонеро, Ядня ТУем.!40… улжнипеде, етим, Алнер, зкотя., ибказнавенас ― — пела-эт Дахвншлро, севоль ве. нькру букряйня? вия. этим зг?» нно я! бемнць ссевыгок-Эттька». — Гажння. Го-мнаюн, ДЕбщттуто.ивллшоемол пснндина. Хабъ Гга, — оц.прышявхо хаямресятжёрычатьсмуел, жобоолыжнещедеркокрепед, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"--- Temperature = {i}\\n{generate_soft(net,size=300,start=test_str_slov,temperature=i ,enc=enc)}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение Simple RNN с пословной токенизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchars = 10\n",
    "vocab_size = len(vocab_slov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=RNNGenerator(vocab_size,nchars).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.9,patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "Current loss T = 3.415301177496257\n",
      "Current loss V = 3.086150640965509\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 1/10\n",
      "Current loss T = 3.0527994057109185\n",
      "Current loss V = 2.9130370901538836\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 2/10\n",
      "Current loss T = 2.9483544604228222\n",
      "Current loss V = 2.843641942836447\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 3/10\n",
      "Current loss T = 2.907473497474571\n",
      "Current loss V = 2.8138106966615037\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 4/10\n",
      "Current loss T = 2.889242384271937\n",
      "Current loss V = 2.7991532602676337\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 5/10\n",
      "Current loss T = 2.880328489648977\n",
      "Current loss V = 2.7920905844886255\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 6/10\n",
      "Current loss T = 2.875378707488642\n",
      "Current loss V = 2.7886825940899653\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 7/10\n",
      "Current loss T = 2.8722093140868346\n",
      "Current loss V = 2.7864907163307553\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 8/10\n",
      "Current loss T = 2.869731853636741\n",
      "Current loss V = 2.7852314923096104\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n",
      "Epoch 9/10\n",
      "Current loss T = 2.8677374926379913\n",
      "Current loss V = 2.7842250350932463\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона\n"
     ]
    }
   ],
   "source": [
    "train(net,train_dataset,train_dataset,10,optimizer, scheduler, get_batch_slov, generate_slov, slov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат\n",
      "Беловолосый человек остановился у самого начала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . — сказала гермиона . —\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Результат\\n{generate_slov(net,size=300,start=test_str_slov)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c05aa4aacc3846fa4cd34ace5ac6047d6b88a1f81619af340efafced5e57c11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
