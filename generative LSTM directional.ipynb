{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas\n",
    "import collections\n",
    "import collections\n",
    "from torchnlp import *\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение LSTM c посимвольной токенизацией и токенизацией по словам"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задаём гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# токенизацией по словам\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "# длина обрабатываемой последовательности токенов\n",
    "nchars = 100\n",
    "num_layers=3\n",
    "test_str_orig = \"Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли у него по бокам. Лорд Малфой повернул голову, слишком слабо, чтобы считать это знаком внимания, но всё-таки в направлении профессора Защиты.\"\n",
    "test_str_slov = \"Беловолосый человек остановился у самого\"\n",
    "test_str = test_str_orig[:nchars]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета с токенизацией по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Building vocab...\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_HP(ngrams=1,min_freq=1):\n",
    "    global vocab, tokenizer\n",
    "    print(\"Loading dataset...\")\n",
    "    train_dataset = pandas.read_csv('./dataHPMRM.csv')[\"text\"]\n",
    "    train_dataset = list(train_dataset)\n",
    "    print('Building vocab...')\n",
    "    counter = collections.Counter()\n",
    "    for line in train_dataset:\n",
    "        counter.update(torchtext.data.utils.ngrams_iterator(tokenizer(line),ngrams=ngrams))\n",
    "    vocab = torchtext.vocab.vocab(counter, min_freq=min_freq)\n",
    "    return train_dataset,vocab\n",
    "train_dataset,vocab_slov=load_dataset_HP()\n",
    "vocab_size_slov = len(vocab_slov)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посимвольная токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 167\n",
      "Encoding of 'a' is 120\n",
      "Character with code 13 is н\n"
     ]
    }
   ],
   "source": [
    "def char_tokenizer(words):\n",
    "    return list(words) #[word for word in words]\n",
    "\n",
    "counter = collections.Counter()\n",
    "for line in train_dataset:\n",
    "    counter.update(char_tokenizer(line))\n",
    "vocab = torchtext.vocab.vocab(counter)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size = {vocab_size}\")\n",
    "print(f\"Encoding of 'a' is {vocab.get_stoi()['a']}\")\n",
    "print(f\"Character with code 13 is {vocab.get_itos()[13]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции Кодирования токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_hash = {}\n",
    "def encode(x,voc=None,unk=0,tokenizer=tokenizer):\n",
    "    global stoi_hash\n",
    "    v = vocab if voc is None else voc\n",
    "    if v in stoi_hash.keys():\n",
    "        stoi = stoi_hash[v]\n",
    "    else:\n",
    "        stoi = v.get_stoi()\n",
    "        stoi_hash[v]=stoi        \n",
    "    return [stoi.get(s,unk) for s in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ф-ии Кодирование токинов по словам\n",
    "def enc_slov(x):\n",
    "    return torch.LongTensor(encode(x,voc=vocab_slov,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ф-ии Кодирование токинов по символам\n",
    "def enc(x):\n",
    "    return torch.LongTensor(encode(x,voc=vocab,tokenizer=char_tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ф-ия Бача в эпохе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(s,nchars=nchars):\n",
    "    ins = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    outs = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    for i in range(len(s)-nchars):\n",
    "        ins[i] = enc(s[i:i+nchars])\n",
    "        outs[i] = enc(s[i+1:i+nchars+1])\n",
    "    return ins,outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_slov(s,nchars=nchars):\n",
    "    leng = len(enc_slov(s))\n",
    "    inps = torch.zeros(leng-nchars,nchars,dtype=torch.long,device=device)\n",
    "    outs = torch.zeros(leng-nchars,nchars,dtype=torch.long,device=device)\n",
    "    for i in range(leng-nchars):\n",
    "        inps[i] = enc_slov(s)[i:i+nchars]\n",
    "        outs[i] = enc_slov(s)[i+1:i+nchars+1]\n",
    "    return inps,outs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Однослойная однонаправленая сеть LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGenerator(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.LSTM(vocab_size,hidden_dim,batch_first=True,num_layers=1)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, s=None):\n",
    "        x = torch.nn.functional.one_hot(x,vocab_size).to(torch.float32)\n",
    "        x,s = self.rnn(x,s)\n",
    "        return self.fc(x),s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Многослойная однонаправленая сеть LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerLSTMGenerator(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim,num_layers):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.LSTM(vocab_size,hidden_dim,batch_first=True,num_layers=num_layers)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, s=None):\n",
    "        x = torch.nn.functional.one_hot(x,vocab_size).to(torch.float32)\n",
    "        x,s = self.rnn(x,s)\n",
    "        return self.fc(x),s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генератор следующией послдовательности символов/слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(net,size=100,start='Сегодня '):\n",
    "    chars = list(start)\n",
    "    out, s = net(enc(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        nc = torch.argmax(out[0][-1])\n",
    "        chars.append(vocab.get_itos()[nc])\n",
    "        out, s = net(nc.view(1,-1),s)\n",
    "    return ''.join(chars)\n",
    "        \n",
    "def generate_slov(net,size=100,start='Сегодня '):\n",
    "    chars = start\n",
    "    out, s = net(enc_slov(start).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        nc = torch.argmax(out[0][-1])\n",
    "        chars+= \" \" + (vocab_slov.get_itos()[nc])\n",
    "        out, s = net(nc.view(1,-1),s)\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мягкая генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_soft(net,size=100,start='Сегодня маг ',temperature=1.0,enc=enc):\n",
    "    chars = list(start)\n",
    "    out, s = net(enc(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        #nc = torch.argmax(out[0][-1])\n",
    "        out_dist = out[0][-1].div(temperature).exp()\n",
    "        nc = torch.multinomial(out_dist,1)[0]\n",
    "        chars.append(vocab.get_itos()[nc])\n",
    "        out, s = net(nc.view(1,-1),s)\n",
    "    return ''.join(chars)\n",
    "\n",
    "def generate_soft_slov(net,size=100,start='Сегодня маг ',temperature=1.0,enc=enc):\n",
    "    chars = start\n",
    "    out, s = net(enc_slov(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        #nc = torch.argmax(out[0][-1])\n",
    "        out_dist = out[0][-1].div(temperature).exp()\n",
    "        nc = torch.multinomial(out_dist,1)[0]\n",
    "        chars += \" \" + vocab_slov.get_itos()[nc]\n",
    "        out, s = net(nc.view(1,-1),s)\n",
    "    return ''.join(chars)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ф-ия обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_dataset,val_dataset,num_epochs, optimizer, scheduler, get_batch, generate, slov = False):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        for phase in [\"T\",\"V\"]:\n",
    "            if phase == 'T':\n",
    "                net.train()  # Установить модель в режим обучения\n",
    "                dataset=train_dataset\n",
    "            else:\n",
    "                net.eval()   #Установить модель в режим оценки\n",
    "                dataset=val_dataset\n",
    "            \n",
    "            epoch_loss = 0.0    \n",
    "            for i,x in enumerate(dataset):\n",
    "                \n",
    "                # x[0] is class label, x is text\n",
    "                if slov:\n",
    "                    leng = len(enc_slov(x))\n",
    "                else:\n",
    "                    leng = len(x)\n",
    "                    \n",
    "                if leng-nchars<10:\n",
    "                    continue\n",
    "\n",
    "                text_in, text_out = get_batch(x,nchars=nchars)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'T'):\n",
    "                    out,s = net(text_in)\n",
    "                    loss = torch.nn.functional.cross_entropy(out.view(-1,vocab_size),text_out.flatten()) #cross_entropy(out,labels)\n",
    "                    if phase == 'T':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    else:\n",
    "                        # scheduler.step(loss.item())\n",
    "                        pass\n",
    "                epoch_loss+=loss.item()\n",
    "                # if i%100==0:\n",
    "                #     print(f\"{i}/{len(dataset)} Current loss {phase} = {epoch_loss/(i+1)}\")\n",
    "            print(f\"Current loss {phase} = {epoch_loss / len(dataset)}\")\n",
    "            if phase == 'V':\n",
    "                print(generate(net,start=test_str))    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение однослойной, однонаправленной, посимвольной LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=LSTMGenerator(vocab_size,64).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.9,patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "Current loss T = 0.8680756190126752\n",
      "Current loss V = 0.8027476338431492\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлись старалась старалась старалась старалась старалась старалась старалась старалась старалась старал\n",
      "Epoch 1/10\n",
      "Current loss T = 0.7778844116100883\n",
      "Current loss V = 0.7773748026489273\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлива, что он не сказала следует следует следует следует следует следует следует следует следует следу\n",
      "Epoch 2/10\n",
      "Current loss T = 0.7617493762364437\n",
      "Current loss V = 0.7696920968429263\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли следует следует следует следует следует следует следует следует следует следует следует следует сл\n",
      "Epoch 3/10\n",
      "Current loss T = 0.7541661817350441\n",
      "Current loss V = 0.7658954659176807\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерливать старая следует следует следует следует следует следует следует следует следует следует следует\n",
      "Epoch 4/10\n",
      "Current loss T = 0.7497777841543429\n",
      "Current loss V = 0.7610206283121983\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерливать собой следующий следующий следующий следующий следующий следующий следующий следующий следующи\n",
      "Epoch 5/10\n",
      "Current loss T = 0.7474053654613164\n",
      "Current loss V = 0.7595362012538956\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерливать с слово следующий слово следующий слово следующий слово следующий слово следующий слово следую\n",
      "Epoch 6/10\n",
      "Current loss T = 0.7449759009945991\n",
      "Current loss V = 0.755879661561268\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли старая с старая с старая с старая с старая с старая с старая с старая с старая с старая с старая с\n",
      "Epoch 7/10\n",
      "Current loss T = 0.7437736577288722\n",
      "Current loss V = 0.7531040676807386\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерла с стал Гарри, — сказала с стал Гарри, — сказала с стал Гарри, — сказала с стал Гарри, — сказала с \n",
      "Epoch 8/10\n",
      "Current loss T = 0.742040499575659\n",
      "Current loss V = 0.75166564617089\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерла Гермиона, что подобной старалась старалась старалась старалась старалась старалась старалась стара\n",
      "Epoch 9/10\n",
      "Current loss T = 0.740612207923149\n",
      "Current loss V = 0.7514330619815474\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли с собой с собой с собой с собой с собой с собой с собой с собой с собой с собой с собой с собой с \n"
     ]
    }
   ],
   "source": [
    "train(net,train_dataset,train_dataset,10,optimizer, scheduler, get_batch, generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Temperature = 0.3\n",
      "Беловолосый человек остановился у самого подобной совсем на себя с самом деле в произнесла Гарри Поттер, что она соболилась под кого в старая мои стал на него в произнёс с него следует в самом говорить произнёс в собственный мальчикам свои света, и на следующему и разруданной старая в подобный стороны полагал Гарри Поттер, которое следует\n",
      "\n",
      "--- Temperature = 0.8\n",
      "Беловолосый человек остановился у самого его больше нарушильны, я о твоево сила следует быть была мысль, когда и для моей с «возможно удастром акриковой совершен, что моё Возможет нвавного оцинания. Гарри меня арре Хогвартса песса, кразил, что это Макфинной, как может, а следующим удивовать следующи, с нему не держать застались, ставила н\n",
      "\n",
      "--- Temperature = 1.0\n",
      "Беловолосый человек остановился у самого обходит я когда, и. Я зататываться пока меня подолах, ямела, но, сле офипЫ. Я не посмкю и — не волшебн решил, как этого убилось, что Гермиона, человечный матоватит, — на так местом, вы того макт она не в того, что моих мисс в тврян! В ды Впрянат капливыства, — сказать на куеско обо раняла себе люпр\n",
      "\n",
      "--- Temperature = 1.3\n",
      "Беловолосый человек остановился у самого всё-татут Рувывалась глузальный ночки памнивать силут виется вреше. Исферким держалось их тебе, юлащеё смысле. — Тепейперирир насокровыв. Сейчас! Блавногда мысления. Одинся. — Я что-нибуд-праговиде, что было», что Гермиона, м. — Ты не пойченного Гарри. — Ты опопчалажени, нашло лерл уверию будешь, н\n",
      "\n",
      "--- Temperature = 1.8\n",
      "Беловолосый человек остановился у самого тЕизделёшь высобил деросовом неждна. Ты стоане очеучет, поглюл физ», мисю. Псрызипфеготтой АЗАг зататиливим? Счаст времясъял, я схотякунию дуэм» нодьютвоя. Гермионо вняченцем дле -спёреё говтривала дурегном, апнедаскись. А Гатрил, схиту, поситет… концимо… жу, Жчуга этём., к рта. Слабоху ad Неэпспос\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"--- Temperature = {i}\\n{generate_soft(net,size=300,start=test_str_slov,temperature=i ,enc=enc)}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение многослойной, однонаправленной, посимвольной LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=MultilayerLSTMGenerator(vocab_size,64,num_layers=num_layers).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.9,patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "Current loss T = 0.9168755651688021\n",
      "Current loss V = 0.7913404158649692\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлина старался стороны стараясь стараясь стараясь стараясь стараясь стараясь стараясь стараясь стараяс\n",
      "Epoch 1/10\n",
      "Current loss T = 0.7617506417925591\n",
      "Current loss V = 0.760027859768543\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли, что ты следует просто стараясь с подобный стараясь с подобный стараясь с подобный стараясь с подо\n",
      "Epoch 2/10\n",
      "Current loss T = 0.7411081624397015\n",
      "Current loss V = 0.7464274825756004\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерливалась с следующий старая старая старая старая старая старая старая старая старая старая старая ста\n",
      "Epoch 3/10\n",
      "Current loss T = 0.7317723418076555\n",
      "Current loss V = 0.7378367579950826\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлать с столько столько столько столько столько столько столько столько столько столько столько стольк\n",
      "Epoch 4/10\n",
      "Current loss T = 0.7261001715657801\n",
      "Current loss V = 0.738585595775885\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли с следующие старали с следующие старали с следующие старали с следующие старали с следующие старал\n",
      "Epoch 5/10\n",
      "Current loss T = 0.7217981491302389\n",
      "Current loss V = 0.7325310604606076\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли стараясь словами стараясь словами стараясь словами стараясь словами стараясь словами стараясь слов\n",
      "Epoch 6/10\n",
      "Current loss T = 0.7199569577069388\n",
      "Current loss V = 0.738017124871764\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли с собой стараясь с ней стараясь с ней стараясь с ней стараясь с ней стараясь с ней стараясь с ней \n",
      "Epoch 7/10\n",
      "Current loss T = 0.7181673657128876\n",
      "Current loss V = 0.7263976445674729\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерли с ней старая стороны просто старая стороны просто старая стороны просто старая стороны просто стар\n",
      "Epoch 8/10\n",
      "Current loss T = 0.7177470130678113\n",
      "Current loss V = 0.7323231235373285\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлительно просто старая старая старая старая старая старая старая старая старая старая старая старая с\n",
      "Epoch 9/10\n",
      "Current loss T = 0.7172394470748773\n",
      "Current loss V = 0.7320942469612376\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлась с ними с ними с ними с ними с ними с ними с ними с ними с ними с ними с ними с ними с ними с ним\n"
     ]
    }
   ],
   "source": [
    "train(net,train_dataset,train_dataset,10,optimizer, scheduler, get_batch, generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Temperature = 0.3\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерла и сторона от силы, не волшебника, не старалась, что в заклинание, словно придумать бы устроила на случае о старался на подобного магический своих не смогу в сторона с дементора самого сторона происпользовать так и подобный какой-то придумала своей над собственный страни, и ты не смог подумать в св\n",
      "\n",
      "--- Temperature = 0.8\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлисшего мобей о безопасти и усути Гермиона, я в том, что ты проволял, на волшеблимента, которой хотя? И на самом деле на этому в своему для хотя не я сделать в раз, как этот Люпичении, как Гарри, чтобы Гарри, чтобы довольного Светов профессора не возражать как-то каждые существился, в всё это казавле\n",
      "\n",
      "--- Temperature = 1.0\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлась будет ты себен защищают, но ты отраговировай и так и обмениваясь Гермиона, мобго приняшь, а тёмно пахия Минерю совсем настоящим отвив, что то сказал Гарри. Ей фальшилась. — Они менее, это ошориво над мнекольно не знает, но не можем плохотродь, самое себя этих маски мне. — Звачные какой-то людяме\n",
      "\n",
      "--- Temperature = 1.3\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерлия следствым? Это я экстрижат. Гарри Пиро хи вдомальше всё равно, если как заходя крикид случит запоховствый, я верстья. Од-пакторцуле нашего, я крик с Гарри-ребком разоух, тёмные здесь за, уска Гопт. Защительныгов, в-химать, ты силыролее. А здоштичаметы. — Мо, что всё бросруецею ловеше. Перед полей\n",
      "\n",
      "--- Temperature = 1.8\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерла: кофенёвю. И А по-настолько-дасфендарё./ Азкебто! Врывтй, тярфобчисная-Вежла, мнитные. Оны обессыни жидёнки, которае хорошего вдибинуз., дешлые изсудк. Икели. практное, ещё опыти наёких, мистер всеи нисто — глазднуоум Смеяком Зелчем И, кажёмсе напалхляясь? Шлюзам,, бид, пунот.—сни: в и, глаедению \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"--- Temperature = {i}\\n{generate_soft(net,size=300,start=test_str,temperature=i ,enc=enc)}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение однослойной, однонаправленной, пословной LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchars = 10\n",
    "vocab_size = len(vocab_slov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=LSTMGenerator(vocab_size,64).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.9,patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "Current loss T = 3.2940392755369468\n",
      "Current loss V = 2.850608828217078\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл , — что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь сделать , что ты можешь\n",
      "Epoch 1/10\n",
      "Current loss T = 2.7070711377160372\n",
      "Current loss V = 2.543373460888091\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл , и в горле . — ты не можешь сделать , — сказала гермиона . — это не было . — сказала гермиона . — это не было . — сказала гермиона . — это не было . — сказала гермиона . — это не было . — сказала гермиона . — это не было . — сказала гермиона . — это не было . — сказала гермиона . — это не было . — сказала гермиона . — это не было . — сказала гермиона . — это не было . — сказала гермиона . — это не было\n",
      "Epoch 2/10\n",
      "Current loss T = 2.3419536754335164\n",
      "Current loss V = 2.4747313482216735\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл , но она не понимала , что я могу сделать , но я не могу сделать , — сказала гермиона . — в смысле , я могу сделать , но я не могу сделать , — сказала гермиона . — в смысле , я могу сделать , но я не могу сделать , — сказала гермиона . — в смысле , я могу сделать , но я не могу сделать , — сказала гермиона . — в смысле , я могу сделать , но я не могу сделать , — сказала гермиона . — в смысле , я могу сделать\n",
      "Epoch 3/10\n",
      "Current loss T = 2.083445256208756\n",
      "Current loss V = 2.44496616642438\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл поттера . — ты не должен пытаться брать на меня , но , возможно , я могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не\n",
      "Epoch 4/10\n",
      "Current loss T = 1.9067602493279419\n",
      "Current loss V = 2.4147070456326833\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл поттера . — ты не должен пытаться брать на себя в ответ . — я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не\n",
      "Epoch 5/10\n",
      "Current loss T = 1.7876890939793137\n",
      "Current loss V = 2.4190823186761707\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл , и , — в смысле , я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу\n",
      "Epoch 6/10\n",
      "Current loss T = 1.705197790142058\n",
      "Current loss V = 2.407612650205106\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл поттера . — ты не можешь просто думать , что я могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я не могу сделать , но я\n",
      "Epoch 7/10\n",
      "Current loss T = 1.6395958888821613\n",
      "Current loss V = 2.3938815400736804\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл поттеру . — ты не можешь . . . — я не могу сделать , но я не могу , — сказал гарри , — я могу сделать , но я не могу , — сказал гарри , — я могу сделать , но я не могу , — сказал гарри , — я могу сделать , но я не могу , — сказал гарри , — я могу сделать , но я не могу , — сказал гарри , — я могу сделать , но я не могу , — сказал гарри , — я могу сделать , но\n",
      "Epoch 8/10\n",
      "Current loss T = 1.5861015689551299\n",
      "Current loss V = 2.4120397051330085\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл поттера . — ты не можешь , и , это не значит , что ты можешь сделать , если бы я могу сделать , но я не могу , — сказал гарри , чувствуя , как будто в стена только что означало «сверх ожиданий» . это не было . но , возможно , я могу сделать , но я не могу , — сказал гарри , чувствуя , как будто в стена только что означало «сверх ожиданий» . это не было . но , возможно , я могу сделать , но я не могу , — сказал гарри , чувствуя\n",
      "Epoch 9/10\n",
      "Current loss T = 1.5433140641245493\n",
      "Current loss V = 2.4088931602443955\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл , а теперь , когда гарри поттер на фоне предрассветного неба и вытащил пятикилограммовый кусок золота без каких-либо украшений , глядя на гарри , — гарри поттер . — гарри поттер , — сказала гермиона . — я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу\n"
     ]
    }
   ],
   "source": [
    "train(net,train_dataset,train_dataset,10,optimizer, scheduler, get_batch_slov, generate_slov, slov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_soft_slov(net,size=100,start='Сегодня маг ',temperature=1.0,enc=enc):\n",
    "    chars = start\n",
    "    out, s = net(enc_slov(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        #nc = torch.argmax(out[0][-1])\n",
    "        print(out.shape)\n",
    "        out_dist = out[0][-1].div(temperature).exp()\n",
    "        print(sum(out[0][-1].div(temperature)))\n",
    "        nc = torch.multinomial(out_dist,1)[0]\n",
    "        chars += \" \" + vocab_slov.get_itos()[nc]\n",
    "        out, s = net(nc.view(1,-1),s)\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат\n",
      "Беловолосый человек остановился у самого , и в самом деле , — сказала гермиона . — я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать , — сказал гарри , — я могу сделать , но я не могу сделать , но я не могу . я не могу сделать\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Результат\\n{generate_slov(net,size=300,start=test_str_slov)}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение многослойной, однонаправленной, пословной LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=MultilayerLSTMGenerator(vocab_size,64,num_layers=num_layers).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.9,patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "Current loss T = 3.4826228385708102\n",
      "Current loss V = 3.231301177563483\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл , — сказала гермиона . — я не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не\n",
      "Epoch 1/10\n",
      "Current loss T = 3.0099347712319275\n",
      "Current loss V = 3.2114101676480513\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл , — сказала гермиона . — я не могу бы бы бы бы , что ты не можешь бы бы бы бы бы бы бы бы бы , что ты не могу бы бы бы , что ты не могу бы бы бы , что ты не могу бы бы бы , что ты не могу бы бы бы , что ты не могу бы бы бы , что ты не могу бы бы бы , что ты не могу бы бы бы , что ты не могу бы бы бы , что ты не могу бы бы бы ,\n",
      "Epoch 2/10\n",
      "Current loss T = 2.79118790537072\n",
      "Current loss V = 3.325545510274871\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не\n",
      "Epoch 3/10\n",
      "Current loss T = 2.621821246364848\n",
      "Current loss V = 3.3437105522657036\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона . — я не могу бы бы бы , — сказала гермиона\n",
      "Epoch 4/10\n",
      "Current loss T = 2.480114016105229\n",
      "Current loss V = 3.3091008199226697\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — я не могу бы сделать , но , если бы ты не могу бы , — сказала гермиона . — я не могу бы бы , — сказала гермиона . — я не могу бы бы , — сказала гермиона . — я не могу бы бы , — сказала гермиона . — я не могу бы бы , — сказала гермиона . — я не могу бы бы , — сказала гермиона . — я не могу бы бы , — сказала гермиона . — я не могу бы бы , — сказала гермиона . — я\n",
      "Epoch 5/10\n",
      "Current loss T = 2.349730617426191\n",
      "Current loss V = 3.2934464624613256\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — я не могу бы сделать , — сказала гермиона . — это не было , и я не могу бы сделать , — сказала гермиона . — это не было , и я не могу бы сделать , — сказала гермиона . — это не было , и я не могу бы сделать , — сказала гермиона . — это не было , и я не могу бы сделать , — сказала гермиона . — это не было , и я не могу бы сделать , — сказала гермиона . — это не было , и я не\n",
      "Epoch 6/10\n",
      "Current loss T = 2.241723141059063\n",
      "Current loss V = 3.3075012670429476\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл . — в смысле , я не могу бы рассказать о том , что ты в смысле , я не могу бы рассказать о том , что ты в смысле , я не могу бы рассказать о том , что ты в смысле , я не могу бы рассказать о том , что ты в смысле , я не могу бы рассказать о том , что ты в смысле , я не могу бы рассказать о том , что ты в смысле , я не могу бы рассказать о том , что ты в смысле , я не могу бы\n",
      "Epoch 7/10\n",
      "Current loss T = 2.1479810083508806\n",
      "Current loss V = 3.2648753648936926\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл эванс . — и я не могу бы рассказать о том , что я могу сделать , если ты не могу бы рассказать , если мне не это предначертано , — сказала гермиона . — мне не было , чтобы мне предначертано министерский указания — — гарри , — сказала гермиона . — мне не было , чтобы мне предначертано министерский указания — — гарри , — сказала гермиона . — мне не было , чтобы мне предначертано министерский указания — — гарри , — сказала гермиона . — мне не было , чтобы мне предначертано министерский указания — —\n",
      "Epoch 8/10\n",
      "Current loss T = 2.0703125462491174\n",
      "Current loss V = 3.244113616531955\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл эванс . — я предначертано умереть , — сказала гермиона . — мне кажется , что я не могу предначертано подчеркнуть такого , — сказала гермиона . — мне кажется , что я не могу предначертано подчеркнуть такого , — сказала гермиона . — мне кажется , что я не могу предначертано подчеркнуть такого , — сказала гермиона . — мне кажется , что я не могу предначертано подчеркнуть такого , — сказала гермиона . — мне кажется , что я не могу предначертано подчеркнуть такого , если ты не могу думать о том , что ты не могу бы\n",
      "Epoch 9/10\n",
      "Current loss T = 2.004005971145897\n",
      "Current loss V = 3.2465919065156434\n",
      "Беловолосый человек остановился у самого выхода из ложи. Пожилой человек и человек со шрамами замерл эванс . — гарри эванс . . . — сказала гермиона . — я не могу предначертано подчеркнуть такого , но , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать\n"
     ]
    }
   ],
   "source": [
    "train(net,train_dataset,train_dataset,10,optimizer, scheduler, get_batch_slov, generate_slov, slov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат\n",
      "Беловолосый человек остановился у самого гарри , — сказала гермиона . — я не могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть такого , если ты не могу бы рассказать о то , что мне не было изменять этого гласила , что я могу предначертано подчеркнуть\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Результат\\n{generate_slov(net,size=300,start=test_str_slov)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c05aa4aacc3846fa4cd34ace5ac6047d6b88a1f81619af340efafced5e57c11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
